<span style= "font-size:16px"> **Reflect on the relationship between labels and images in a machine learning image classification dataset? Who has the power to label images and how do those labels and machine learning models trained on them impact society?** </span>
    
  Before reading this article things like ImageNet seemed like they had the potential to be used for less savory purposes, like facial recognition. 
  However, reading this article made me realize how insidious the categories themselves are. Labels on a training set are the only information that a 
  machine learning algorithm is given. So, to learn how to identify anything, it must rely on the initial images and labels. So, associating negative labels 
  with certain groups can be done very easily and widely spread by the computer without a second thought. The article talked about how workers were the ones that were 
  initially labelling images. Which makes sense because someone has to do it. However, this surprised me because I thought that the information came from other details 
  from where the image was from like the original caption, poster, and their profile. But all the labels just come from a person looking at a picture and deciding how 
  to label it. I knew that machine learning has the capability of being biased, but I never fully understood how until now. If someone is racist, sexist, or homophobic, 
  they can just impose their beliefs onto the machine learning algorithm by putting certain pictures of people under categories that are negative or offensive. This 
  impacts society as a whole because as society moves towards more automation, automation has to be able to keep up and live up to people’s expectations. People believe 
  that computers are unbiased, completely true sources of information, untouched by the prejudices of man. So, if a computer were to say that someone committed a crime, 
  it’s much more widely believed than an eyewitness account. The article mentioned another project, one that’s supposed to identify violence. If the training set is 
  theatrical and unlike real life, it could lead to actual consequences for people by having false positives and negatives. Overall, this is perfectly summed up by the 
  painting by Magritte. Images are just images, they are not people. Not everything about a person can be ascertained from an image of them. Acting like one or even three
  people identifying the person in the image can be completely accurate is woefully wrong and harmful for people, especially people who are discriminated against. 
